# -*- coding: utf-8 -*-
"""Assignment 1 and 2 _IIT patna.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17CrGjP4k6ybG8XrdRoLsDgymOgd_E4VA

Assessment 1: Englishâ€“Hindi Dataset Processing and Analysis
"""

# =====================================
# STEP 1: Install required libraries
# =====================================
!pip install datasets pandas openpyxl

# =====================================
# STEP 2: Import Libraries
# =====================================
from datasets import load_dataset
import pandas as pd

# =====================================
# STEP 3: Load Englishâ€“Hindi Dataset
# (Using IITB English-Hindi dataset)
# =====================================
dataset = load_dataset("cfilt/iitb-english-hindi")

# Convert to Pandas DataFrame (train split has ~1.6M rows)
df = pd.DataFrame(dataset['train'])

# Expand the 'translation' dictionary into English and Hindi columns
df = pd.json_normalize(df['translation'])

# Rename columns properly
df = df.rename(columns={"en": "English", "hi": "Hindi"})

print("âœ… Columns available:", df.columns)
print("âœ… Original dataset size:", len(df))
print(df.head())

# =====================================
# STEP 4: Select First 10,000 Rows
# (per assignment requirement)
# =====================================
df = df.head(10000)

# =====================================
# STEP 5: Compute Word Counts
# =====================================
df['WordCount_English'] = df['English'].apply(lambda x: len(str(x).split()))
df['WordCount_Hindi']   = df['Hindi'].apply(lambda x: len(str(x).split()))

# =====================================
# STEP 6: Keep only sentences with
# 5 to 50 words in BOTH languages
# =====================================
df = df[(df['WordCount_English'].between(5, 50)) &
        (df['WordCount_Hindi'].between(5, 50))]

# =====================================
# STEP 7: Calculate Word Count Difference
# =====================================
df['Difference'] = df['WordCount_English'] - df['WordCount_Hindi']

# Keep only differences between -10 and +10
df = df[df['Difference'].between(-10, 10)]

print("âœ… Final dataset size after filtering:", len(df))
print(df.head())

# =====================================
# STEP 8: Save Final Output to Excel
# =====================================
output_file = "/content/cleaned_dataset.xlsx"
df.to_excel(output_file, index=False)

print("ðŸŽ‰ Final cleaned dataset saved as:", output_file)

"""Assessment No. 2 â€“ Translation with LLM

"""

# =====================================
# ASSESSMENT 2 â€“ Translation with LLM
# =====================================

!pip install transformers sacrebleu

from transformers import pipeline
import sacrebleu

# Load the cleaned dataset from Assignment 1
df = pd.read_excel("/content/cleaned_dataset.xlsx")

# Select 100 English sentences with their Hindi references
df_sample = df.head(100)[['English', 'Hindi']]

# Load translation model (English â†’ Hindi)
translator = pipeline("translation", model="Helsinki-NLP/opus-mt-en-hi")

# Generate translations
translations = []
for sentence in df_sample['English']:
    result = translator(sentence, max_length=100)
    translations.append(result[0]['translation_text'])

df_sample['Model_Hindi'] = translations

# Evaluation metrics
refs = df_sample['Hindi'].tolist()
hyps = df_sample['Model_Hindi'].tolist()

bleu = sacrebleu.corpus_bleu(hyps, [refs])
chrf = sacrebleu.corpus_chrf(hyps, [refs])
ter = sacrebleu.corpus_ter(hyps, [refs])

# Save scores in text file
with open("translation_scores.txt", "w", encoding="utf-8") as f:
    f.write(f"BLEU score: {bleu.score:.2f}\n")
    f.write(f"CHRF score: {chrf.score:.2f}\n")
    f.write(f"TER score: {ter.score:.2f}\n")

# Save Excel output
df_sample[['English', 'Model_Hindi']].to_excel("translation_output.xlsx", index=False)

print("âœ… Translation completed!")
print("ðŸ“‚ Files created: translation_output.xlsx & translation_scores.txt")

output_file = "/content/drive/MyDrive/cleaned_dataset.xlsx"
df.to_excel(output_file, index=False)
print("âœ… Cleaned dataset saved to Google Drive:", output_file)

# Save Excel with translations
translation_excel = "/content/drive/MyDrive/translation_output.xlsx"
df_sample[['English', 'Model_Hindi']].to_excel(translation_excel, index=False)

# Save evaluation scores
translation_scores = "/content/drive/MyDrive/translation_scores.txt"
with open(translation_scores, "w", encoding="utf-8") as f:
    f.write(f"BLEU score: {bleu.score:.2f}\n")
    f.write(f"CHRF score: {chrf.score:.2f}\n")
    f.write(f"TER score: {ter.score:.2f}\n")

print("âœ… All files saved in Google Drive:")
print("   â€¢", output_file)
print("   â€¢", translation_excel)
print("   â€¢", translation_scores)